{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a1e4a5",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff98a6e",
   "metadata": {},
   "source": [
    "## Satellite Image Classification \n",
    "\n",
    "Le but de ce projet est de **classifier des images satellites** en 4 catégorie possibles: \"cloudy\", \"desert\", \"green area\" ou \"water\".\n",
    "\n",
    "Pour plus de précision sur les data, voir le lien suivant:<br>\n",
    "https://www.kaggle.com/datasets/mahmoudreda55/satellite-image-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29afdd55",
   "metadata": {},
   "source": [
    "## Exercice\n",
    "\n",
    "\n",
    "### Load Data\n",
    "1. Loadez les data en utilisant le code qui vous est donné. Les data sont loadées dans un dictionnaire de la forme suivante:\n",
    "   ```\n",
    "   data_d = {\"cloudy\" : ([...], [...]), \n",
    "             \"desert\" : ([...], [...]), \n",
    "             \"green_area\" : ([...], [...]), \n",
    "             \"water\" : ([...], [...])}\n",
    "   ```\n",
    "   où pour chaque tuple `([...], [...])`, le premièr élément est une liste de numpy arrays (3D) qui repésentent les images en RGB, et le deuxième élément est une liste de labels associés à ces images.<br>\n",
    "   Examinez ces data et comprenez leur format.\n",
    "\n",
    "\n",
    "### Data Analysis\n",
    "2. Comptez combien il y a d'images de chaque label, pour voir si le dataset est équilibré.\n",
    "\n",
    "\n",
    "### Create Datasets\n",
    "3. Créez une liste `X` qui contient les **images** (liste de numpy 3D-arrays) et une liste `y` qui contient les **labels** de ces images.\n",
    "\n",
    "\n",
    "4. Remarquez qu'il y a des images de dimension `(256, 256, 3)` et d'autres de dimension `(64, 64, 3)`.<br>\n",
    "   En utilisant la fonction `cv2.resize(...)`, redimensionnez toutes les images à la dimension `(64, 64, 3)`.<br>\n",
    "   Vos image seront alors représentées par une liste `X` de numpy arrays de dimension `(64, 64, 3)`.\n",
    "   \n",
    "\n",
    "5. En utilisant la fonction `np.flatten(...)`, aplatissez chaque images de dimension `(64, 64, 3)` en un vecteur de taille `64 * 64 * 3 = 12288`. Vous devez obtenir une liste `X` d'images aplaties (i.e., une liste de 1D-arrays, dont chacun est de taille `12288`).\n",
    "\n",
    "\n",
    "6. En utilisant la fonction `np.stack(...)`, convertissez votre liste d'images aplaties `X` en un numpy array de dimension 2, également appelé `X`.\n",
    "\n",
    "\n",
    "7. En utilisant la fonction `train_test_split(...)`, splittez vos data `X` et `y` en un **train set** et un **test set** de tailles 80% wet 20%, respectivement.\n",
    "\n",
    "\n",
    "### Model\n",
    "9. Fittez une **régression logistique** sur vos data.<br>\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression<br>\n",
    "    Calculer le **rapport de classification (classification report)** relatif à vos prédictions.<br>\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report<br>\n",
    "    L'entrâinement peut prendre du temps... Essayez de \"tuner\" les hyperparamètres pour résussir à entraîner le modèle.\n",
    "\n",
    "\n",
    "10. Fittez un **support vector machine classifier (SVC)** sur vos data:<br>\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC<br>\n",
    "    Calculer le **rapport de classification (classification report)** relatif à vos prédictions.<br>\n",
    "    L'entrâinement peut également prendre du temps...\n",
    "    \n",
    "\n",
    "11. Fittez un **réseau de neurones convolutionnel (CNN)** sur vos data:<br>\n",
    "    https://keras.io/api/layers/convolution_layers/<br>\n",
    "    Calculer le **rapport de classification (classification report)** relatif à vos prédictions.<br>\n",
    "    L'entrâinement peut également prendre du temps..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48c952",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7d17a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install imutils\n",
    "import os\n",
    "import cv2\n",
    "from imutils import paths\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf486b42",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8168d07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jeremie.cabessau-paris2.fr/Desktop/MAIN/Courses/BUT/R4.04_MethOptim/TP'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5496e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudy_img = list(paths.list_files(\"./Data/SatelliteData/cloudy/\"))\n",
    "desert_img = list(paths.list_files(\"./Data/SatelliteData/desert/\"))\n",
    "green_area_img = list(paths.list_files(\"./Data/SatelliteData/green_area/\"))\n",
    "water_img = list(paths.list_files(\"./Data/SatelliteData/water/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e580912",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l = [cloudy_img, desert_img, green_area_img, water_img]\n",
    "data_d = {\"cloudy\" : ([], []), \n",
    "          \"desert\" : ([], []), \n",
    "          \"green_area\" : ([], []), \n",
    "          \"water\" : ([], [])}\n",
    "labels = [\"cloudy\", \"desert\", \"green_area\", \"water\"]\n",
    "\n",
    "for key, data in zip(labels, data_l):\n",
    "\n",
    "    for img in data:\n",
    "    \n",
    "        img = cv2.imread(img)\n",
    "        data_d[key][0].append(img)\n",
    "        data_d[key][1].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495a87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb570ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed2c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f75776",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6692df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd41873a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeca38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b315ad0",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e4eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa16d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c877c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c21474d8",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3f912",
   "metadata": {},
   "source": [
    "### Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752904d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69fb0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e72dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af3662d8",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classifier (SVC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9c5426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c57466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed646e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
