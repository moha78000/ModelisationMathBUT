{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbres de décision dans un contexte de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Activity Recognition\n",
    "\n",
    "Le but de ce projet est de **prédire le type d'activité d'une personne** (variable `Activity`) en fonction de diverses mesures obtenues à l'aide de senseurs. Les différentes activités sont:\n",
    "- STANDING (être debout)\n",
    "- SITTING (être assis)\n",
    "- LAYING (être couché)\n",
    "- WALKING (marcher)\n",
    "- WALKING_DOWNSTAIRS (marcher vers le bas)\n",
    "- WALKING_UPSTAIRS  (marcher vers le haut)\n",
    "\n",
    "Pour plus de précision sur les data, voir le lien suivant:<br>\n",
    "https://www.kaggle.com/datasets/uciml/human-activity-recognition-with-smartphones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice\n",
    "\n",
    "\n",
    "### Load Data\n",
    "1. Loadez les data.<br>\n",
    "   ```\n",
    "   train_df = pd.read_csv('./data/HumanActivity/train.csv')\n",
    "   test_df = pd.read_csv('./data/HumanActivity/test.csv')\n",
    "   ```\n",
    "\n",
    "\n",
    "### Data Analysis\n",
    "2. Vérifiez s'il existe des data dupliquées ou manquantes:<br>\n",
    "   ```\n",
    "   train_df.duplicated().sum()\n",
    "   train_df.isna().values.sum()\n",
    "   ```\n",
    "\n",
    "\n",
    "3. Visualisez la répartition des valeurs de la variable `Activity` à prédire:<br> \n",
    "   ```\n",
    "   sns.countplot(train_df.Activity, order=train_df.Activity.value_counts().index)\n",
    "   ```\n",
    "\n",
    "\n",
    "4. **Principal Component Analysis (PCA)** est une méthode qui réduit la dimension des data selon un critère de maximisation d'explicabilité de leur variance...<br>\n",
    "   Effectuez une PCA de dimension 2 sur votre train set (sans les colonnes `Activity` et `subject`) et visualisez vos data de dimensions réduites:<br>\n",
    "   ```\n",
    "   # PCA\n",
    "   ...\n",
    "   pca = PCA(n_components=2, random_state=0).fit_transform(X_train_modified)\n",
    "   # plot\n",
    "   ...\n",
    "   sns.scatterplot(x=pca[:, 0], y=pca[:, 1], hue=train_df['Activity'])\n",
    "   ...\n",
    "   ```\n",
    "   \n",
    "   \n",
    "5. **t-Distributed Stochastic Neighbor Embedding (t-SNE)** est une méthode plus avancée que PCA pour la réduction de dimension, et donc la visualisation des data.<br>\n",
    "   Effectuez un t-SNE de dimension 2 sur votre train set (sans les colonnes `Activity` et `subject`) et visualisez vos data de dimensions réduites:<br>\n",
    "      ```\n",
    "   # t-SNE\n",
    "   ...\n",
    "   tsne = TSNE(n_components=2, random_state=0, n_iter=1000).fit_transform(X_train_modified)\n",
    "   # plot\n",
    "   ...\n",
    "   sns.scatterplot(x=tsne[:, 0], y=tsne[:, 1], hue=train_df['Activity'])\n",
    "   ...\n",
    "   ```\n",
    "\n",
    "### Data Preprocessing and Splitting\n",
    "6. Obtenez les **features** `X` et les **targets** `y` à partir de votre dataframe.<br>\n",
    "    Les **features** corrrespondent à toutes les colonnes sauf `Activity` et `subject`.<br>\n",
    "    Les **targets** corrrespondent à la colonne `Activity`.<br>\n",
    "    Utilisez `df.drop(...)`.\n",
    "\n",
    "\n",
    "7. Dans le cas présent, il n'y a pas besoin de splittez les data en un **train set** et un **test set**, car ceci est déjà effectué...\n",
    "\n",
    "\n",
    "### Model and Results\n",
    "8. Instanciez et entraînez un **arbre de décision** `DecisionTreeClassifier` sur vos data:<br>\n",
    "   https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html<br>\n",
    "    Le processus s'effectue en 3 étapes:\n",
    "    1. Instanciation du modèle\n",
    "    2. Entraînement du modèle sur le train set (méthode `fit(...)`)\n",
    "    3. Prédictions sur le test set\n",
    "\n",
    "\n",
    "9. Calculez ensuite le **rapport de classification** de votre modèle sur le test set:<br>\n",
    "    Que représentent la **precision**, le **recall**, l'**accuracy** et le **F1-score**?<br>\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html<br>    \n",
    "\n",
    "    \n",
    "### Other Models\n",
    "10. Entraînez également les modèles suivants de `scikit-learn`. Vous pouvez vous référer à la documentation de ces modèles pour plus d'information sur leurs utilisations.<br>\n",
    "    1. `LogisiticRegression`\n",
    "    2. `RandomForestClassifier`\n",
    "\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "11. Utilisez technique de **grid search** avec **cross validation** pour optimiser les hyperparamètres d'un random forest (prend du temps).<br>\n",
    "    Faites varier les paramètres du modèle au sein des valeurs suivantes:<br>\n",
    "    ```\n",
    "    rf_params = {\"max_depth\": [3, 5, 8, None],\n",
    "             \"max_features\": [3, 5, 10],\n",
    "             \"min_samples_split\": [2, 5, 10],\n",
    "             \"min_samples_leaf\": [1, 3, 5, 10],\n",
    "             \"bootstrap\": [True, False],\n",
    "             \"n_estimators\": [100, 500, 1000],\n",
    "             \"random_state\": [42]}\n",
    "    ```\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T15:30:43.780131Z",
     "iopub.status.busy": "2022-12-26T15:30:43.779634Z",
     "iopub.status.idle": "2022-12-26T15:30:44.582926Z",
     "shell.execute_reply": "2022-12-26T15:30:44.581364Z",
     "shell.execute_reply.started": "2022-12-26T15:30:43.780092Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/HumanActivity/train.csv')\n",
    "test_df = pd.read_csv('./data/HumanActivity/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Models\n",
    "### Logistic Regression, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
